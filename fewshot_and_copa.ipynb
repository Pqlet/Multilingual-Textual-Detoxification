{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59e56d9-68e4-4de5-9477-7b838fb169e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd361f39-9569-4328-9ac1-1985bcc0e025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26885f58-5382-4fab-823d-64ec9f917afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece] sentencepiece -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b408a8",
   "metadata": {},
   "source": [
    "## Few-shot experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f43b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46553a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "class PropmtSpitter:\n",
    "    def __init__(self, detox_examples):\n",
    "        self.detox_examples = detox_examples\n",
    "\n",
    "    def __call__(self, input_text, lang=None):\n",
    "        # prompt = (\"Rewrite input toxic text \"\n",
    "        # \"as neutral by replacing toxing words with neutral words or by removing \"\n",
    "        # \"them completely. Here are some examples:\")\n",
    "        prompt=\"\"\n",
    "        if lang is None:\n",
    "            try:\n",
    "                lang = detect(input_text)[:2]\n",
    "            except LangDetectException:\n",
    "                lang = 'am' # only one not supported in langdetect lib\n",
    "\n",
    "        idx = random.sample(range(len(self.detox_examples[lang])), 3)\n",
    "        few_shot_examples = list(zip(\n",
    "            [self.detox_examples[lang][\"toxic_sentence\"][i] for i in idx],\n",
    "            [self.detox_examples[lang][\"neutral_sentence\"][i] for i in idx]\n",
    "        ))\n",
    "\n",
    "        for tox_sent, neut_sent in few_shot_examples:\n",
    "            prompt += '\\nToxic text: ' + tox_sent\n",
    "            prompt += '\\nNeutral text: ' + neut_sent\n",
    "\n",
    "        prompt += '\\nToxic text: ' + input_text + '\\nNeutral text: '\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_hf = load_dataset(\"textdetox/multilingual_paradetox\")   # this is our dataset for competitoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spitter = PropmtSpitter(dataset_hf)\n",
    "print(spitter(\"You little piece of shit!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/mGPT\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/mGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee87c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = ['en', 'ru', 'uk', 'de', 'es', 'am', 'zh', 'ar', 'hi']\n",
    "for lang in lang_codes:\n",
    "    idx = random.sample(range(len(dataset_hf[lang])), 1)\n",
    "    toxic_example = dataset_hf[lang][idx[0]][\"toxic_sentence\"]\n",
    "    neutral_example = dataset_hf[lang][idx[0]][\"neutral_sentence\"]\n",
    "\n",
    "    print(\"Toxic example: \" + toxic_example)\n",
    "    print(\"Neutral example: \" + neutral_example)\n",
    "\n",
    "    prompted_input = spitter(toxic_example)\n",
    "    input_ids = tokenizer(prompted_input, return_tensors=\"pt\").input_ids\n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        min_length=20,\n",
    "        max_length=512,\n",
    "        eos_token_id=5,\n",
    "        #pad_token=1,\n",
    "        do_sample=True,\n",
    "        top_k=0,\n",
    "        top_p=0.8,\n",
    "        no_repeat_ngram_size=4\n",
    "    )\n",
    "\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    detox_generation = generated_text.split(\"Neutral text:\")[-1]\n",
    "    print(\"Model output: \" + detox_generation)\n",
    "    print(\"\\n\")\n",
    "    print(\"---\"*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6277e3f",
   "metadata": {},
   "source": [
    "Problems with tried approaches:\n",
    "- llama - they don't give weights to me (raaaaurgh)\n",
    "- flan-T5 - published model works only with english, other languages suck\n",
    "- mGPT (by sber) - halucinates and duplicates input\n",
    "\n",
    "New thing to try:\n",
    "\n",
    "- produce predictions by delete_ baseline and mt5_baseline\n",
    "- zero-shot pretrained multilingual model (like ) in COPA style task (selection between alternative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0d163",
   "metadata": {},
   "source": [
    "### COPA (Choise of Plausible Alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92769bd-a17f-4e84-891b-52b27ed84ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6910489-fe06-43da-9087-fb10bde66d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_predictions = pd.read_csv('mt5_sub_dev.tsv', sep='\\t')\n",
    "delete_predictions = pd.read_csv('delete_baseline_dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f04b9c-1cdf-4e4f-ba06-7f8f7832ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt5_predictions = mt5_predictions.sort_values(by=['lang', 'toxic_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991ecbc8-59ce-40a4-800a-0405b2e1dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_predictions = delete_predictions.sort_values(by=['lang', 'toxic_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b25206f-1002-4027-9ba1-bc729f52cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eba50032d62409ba6be35655dc35329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3060bab3f3e48668de367d64b5572c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba445d161184dfd95bdbb7972044044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/276 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc06ecb81c54f959c1a10336d4b5a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2459dab529024073941c5ce72053cc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3103b6c704a8413581c2ae3ebf6b644c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d111d3d292e4e2d812e9c17e8708e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import XGLMTokenizer, XGLMForCausalLM\n",
    "\n",
    "model_id=\"xglm-1.7B\"\n",
    "tokenizer = XGLMTokenizer.from_pretrained(f\"facebook/{model_id}\")\n",
    "model = XGLMForCausalLM.from_pretrained(f\"facebook/{model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c71e53b-3888-462d-8c85-9ce408e557e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a6415ea-3d63-4a47-bb8b-f7f19193b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 3600/3600 [06:52<00:00,  8.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad\n",
    "def get_logprobs(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k].cuda()\n",
    "    \n",
    "    input_ids, output_ids = inputs[\"input_ids\"], inputs[\"input_ids\"][:, 1:]\n",
    "    outputs = model(**inputs, labels=input_ids)\n",
    "    logits = outputs.logits\n",
    "    logprobs = torch.gather(F.log_softmax(logits, dim=2), 2, output_ids.unsqueeze(2))\n",
    "    return logprobs\n",
    "\n",
    "@torch.no_grad\n",
    "def copa_eval(prompt, alternative1, alternative2):\n",
    "    lprob1 = get_logprobs(prompt + \"\\n\" + alternative1).sum()\n",
    "    lprob2 = get_logprobs(prompt + \"\\n\" + alternative2).sum()\n",
    "    return 0 if lprob1 > lprob2 else 1\n",
    "\n",
    "copa_predictions = []\n",
    "model.eval()\n",
    "for idx in tqdm(range(len(mt5_predictions))):\n",
    "    row1 = mt5_predictions.iloc[idx]\n",
    "    row2 = delete_predictions.iloc[idx]\n",
    "\n",
    "    toxic_premise = row1[\"toxic_sentence\"]\n",
    "    alt1 = row1[\"neutral_sentence\"]\n",
    "    alt2 = row2[\"neutral_sentence\"]\n",
    "    prompt = f'Is sentence {toxic_premise} close to '\n",
    "\n",
    "    predict = copa_eval(prompt, alt1, alt2)\n",
    "    copa_predictions.append(alt1 if predict == 0 else alt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b446407-2c98-4169-a49a-741f5cd79907",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_subm_df = mt5_predictions.copy()\n",
    "copa_subm_df[\"neutral_sentence\"] = copa_predictions\n",
    "copa_subm_df = copa_subm_df.sort_index()\n",
    "copa_subm_df.to_csv(f\"copa_xglm_{model_id}_submission.tsv\", index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
